# Sampling Server Example

A comprehensive demonstration of **MCP sampling functionality** for AI model sampling through the Model Context Protocol. This example shows how MCP servers can request AI model generation from clients, enabling intelligent workflows and AI-assisted processing.

## Overview

MCP sampling allows servers to request AI model generation from clients through the `sampling/createMessage` endpoint. This enables powerful workflows where MCP servers can leverage AI models for content generation, analysis, and intelligent processing while maintaining separation of concerns between server logic and AI capabilities.

## Features

### 🤖 **AI Model Integration**
- **Direct AI sampling** via `sampling/createMessage` endpoint
- **Model preferences** and constraints specification
- **Temperature and token controls** for generation quality
- **Context-aware prompting** with conversation history

### 💬 **Conversational AI**
- **Multi-turn conversations** with message history
- **Context preservation** across sampling requests
- **Role-based messaging** (user, assistant, system)
- **Conversation metadata** tracking and management

### 💻 **Specialized Sampling**
- **Code generation** with language-specific prompting
- **Creative writing** with style and genre controls
- **Technical analysis** with structured output formats
- **Problem-solving** with methodical approaches

### ⚙️ **Advanced Configuration**
- **Model hints** for optimal model selection
- **Cost budgets** and latency priorities
- **Stop sequences** and output constraints
- **Performance targets** and quality thresholds

## Quick Start

### 1. Start the Server

```bash
cargo run -p sampling-server
```

The server will start on `http://127.0.0.1:8051/mcp`

### 2. Test Sampling Endpoint

```bash
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "method": "sampling/createMessage",
    "params": {
      "messages": [
        {
          "role": "user",
          "content": {
            "type": "text",
            "text": "Hello AI! Please introduce yourself."
          }
        }
      ]
    }
  }'
```

**Example Response:**
```json
{
  "result": {
    "message": {
      "role": "assistant",
      "content": {
        "type": "text",
        "text": "This is a sample message generated by the MCP server"
      }
    },
    "stop_reason": "stop"
  }
}
```

## Sampling Tools

### 1. Basic Sampling

```bash
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "method": "tools/call",
    "params": {
      "name": "basic_sampling",
      "arguments": {
        "prompt": "Explain quantum computing in simple terms"
      }
    }
  }'
```

### 2. Conversational Sampling

```bash
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "method": "tools/call",
    "params": {
      "name": "conversational_sampling",
      "arguments": {
        "user_message": "What are the benefits of renewable energy?",
        "conversation_context": "educational"
      }
    }
  }'
```

### 3. Code Generation Sampling

```bash
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "method": "tools/call",
    "params": {
      "name": "code_generation_sampling",
      "arguments": {
        "task_description": "Create a function to calculate Fibonacci numbers",
        "programming_language": "Python",
        "complexity_level": "intermediate"
      }
    }
  }'
```

### 4. Creative Writing Sampling

```bash
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "method": "tools/call",
    "params": {
      "name": "creative_writing_sampling",
      "arguments": {
        "writing_prompt": "A mysterious door appears in an ordinary room",
        "genre": "fantasy",
        "style": "atmospheric",
        "length": "medium"
      }
    }
  }'
```

### 5. Advanced Sampling Demo

```bash
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "method": "tools/call",
    "params": {
      "name": "advanced_sampling_demo",
      "arguments": {
        "task_type": "analysis",
        "complexity_level": "advanced",
        "output_format": "structured"
      }
    }
  }'
```

## Sampling Request Structure

### Basic Message Structure

```json
{
  "method": "sampling/createMessage",
  "params": {
    "messages": [
      {
        "role": "user|assistant|system",
        "content": {
          "type": "text",
          "text": "Message content here"
        }
      }
    ],
    "model_preferences": {
      "hints": ["conversational", "helpful"],
      "cost_budget": 0.05,
      "latency_priority": "balanced"
    },
    "system_prompt": "You are a helpful AI assistant...",
    "temperature": 0.7,
    "max_tokens": 500,
    "stop_sequences": ["```", "END"],
    "metadata": {
      "session_id": "uuid-here",
      "task_type": "generation"
    }
  }
}
```

### Model Preferences

| Field | Description | Example Values |
|-------|-------------|----------------|
| `hints` | Model selection hints | `["conversational", "technical"]` |
| `cost_budget` | Maximum cost per request | `0.05` (5 cents) |
| `latency_priority` | Speed vs quality trade-off | `"fast", "balanced", "quality"` |

### Generation Parameters

| Parameter | Purpose | Range | Default |
|-----------|---------|-------|---------|
| `temperature` | Creativity vs precision | 0.0 - 1.0 | 0.7 |
| `max_tokens` | Response length limit | 1 - 4000 | 500 |
| `stop_sequences` | Generation stop triggers | Array of strings | `[]` |

## Use Cases

### 1. **Content Generation Workflows**
- **Blog post creation** with topic and style specifications
- **Technical documentation** with code examples and explanations
- **Creative content** for marketing and storytelling
- **Educational materials** with appropriate complexity levels

### 2. **Code Development Assistance**
- **Algorithm implementation** with language-specific best practices
- **Code review and suggestions** with improvement recommendations  
- **Bug analysis and debugging** with step-by-step solutions
- **API documentation** with usage examples and patterns

### 3. **Interactive AI Applications**
- **Chatbot backends** with conversation state management
- **Virtual assistants** with context-aware responses
- **Educational tutors** with adaptive explanations
- **Creative writing partners** with collaborative storytelling

### 4. **Data Analysis and Insights**
- **Report generation** with structured analysis and conclusions
- **Data interpretation** with trend identification and insights
- **Research assistance** with source evaluation and synthesis
- **Decision support** with pros/cons analysis and recommendations

## Architecture

```
┌─────────────────────┐    ┌──────────────────────┐    ┌─────────────────────┐
│   MCP Client        │────│  Sampling Handler    │────│  AI Model          │
│                     │    │                      │    │                     │
│ - Receives Request  │    │ - Process Parameters │    │ - Generate Content  │
│ - Invokes AI Model  │    │ - Build Prompts      │    │ - Apply Constraints │
│ - Returns Response  │    │ - Handle Context     │    │ - Optimize Output   │
│                     │    │ - Manage Sessions    │    │                     │
└─────────────────────┘    └──────────────────────┘    └─────────────────────┘
                                       │
                                       ▼
                           ┌──────────────────────┐
                           │  MCP Server Tools    │
                           │                      │
                           │ - Basic Sampling     │
                           │ - Conversational     │
                           │ - Code Generation    │
                           │ - Creative Writing   │
                           │ - Advanced Features  │
                           └──────────────────────┘
```

## Advanced Features

### 🎯 **Specialized Prompting**

```rust
let system_prompt = format!(
    "You are an expert {} programmer. Generate clean, well-documented, and efficient code. 
     Follow best practices for {} development. Complexity level: {}.",
    language, language, complexity
);

let request = CreateMessageRequest {
    messages: vec![user_message],
    model_preferences: Some(ModelPreferences {
        hints: Some(vec!["code_generation".to_string(), language.to_lowercase()]),
        ..Default::default()
    }),
    system_prompt: Some(system_prompt),
    temperature: Some(0.3), // Lower for deterministic code
    max_tokens: Some(1500),
    // ...
};
```

### 🔄 **Context Management**

```rust
// Build conversation history
let mut messages = vec![
    SamplingMessage {
        role: "assistant".to_string(),
        content: MessageContent::Text {
            text: "Hello! I'm ready to help.".to_string(),
        },
    },
    SamplingMessage {
        role: "user".to_string(),
        content: MessageContent::Text {
            text: user_message.to_string(),
        },
    },
];

let request = CreateMessageRequest {
    messages,
    include_context: Some("conversation_history".to_string()),
    metadata: Some(serde_json::json!({
        "conversation_id": uuid,
        "context_type": "educational"
    })),
    // ...
};
```

### ⚙️ **Performance Optimization**

```rust
let request = CreateMessageRequest {
    model_preferences: Some(ModelPreferences {
        hints: Some(vec!["analytical", "structured"]),
        cost_budget: Some(0.05),          // 5 cents max
        latency_priority: Some("balanced".to_string()),
        ..Default::default()
    }),
    temperature: Some(0.4),               // Precise analysis
    max_tokens: Some(1000),               // Adequate length
    stop_sequences: Some(vec!["}".to_string()]), // JSON completion
    metadata: Some(serde_json::json!({
        "performance_target": {
            "max_latency_ms": 5000,
            "cost_budget": 0.05,
            "quality_threshold": 0.8
        }
    })),
    // ...
};
```

## Best Practices

### 🎯 **Effective Prompting**
1. **Clear Instructions**: Provide specific, actionable prompts
2. **Context Setting**: Use system prompts to establish role and behavior
3. **Constraint Specification**: Define output format, length, and style requirements
4. **Example Provision**: Include examples for complex output formats

### ⚡ **Performance Optimization**
1. **Temperature Tuning**: Lower for factual content (0.3), higher for creativity (0.8)
2. **Token Management**: Set appropriate max_tokens to balance cost and completeness
3. **Stop Sequences**: Use to prevent over-generation and ensure format compliance
4. **Model Hints**: Provide hints for optimal model selection and behavior

### 🔒 **Security and Quality**
1. **Input Validation**: Sanitize user inputs before sending to AI models
2. **Output Filtering**: Validate AI responses for appropriate content and format
3. **Cost Control**: Set reasonable cost budgets to prevent runaway expenses
4. **Error Handling**: Implement robust error handling for API failures

### 📊 **Monitoring and Analytics**
1. **Request Tracking**: Log sampling requests with metadata for analysis
2. **Performance Metrics**: Monitor latency, cost, and quality scores
3. **Usage Patterns**: Analyze which sampling types are most effective
4. **Quality Assessment**: Implement feedback mechanisms for continuous improvement

## Real-world Applications

### 1. **Content Management Systems**
- **Automated content creation** with brand voice consistency
- **SEO optimization** with keyword integration and readability analysis
- **Multi-language content** with cultural adaptation and localization
- **Content categorization** with automatic tagging and metadata

### 2. **Developer Tools**
- **Code generation IDEs** with context-aware suggestions
- **API documentation generators** with example code and explanations
- **Test case creation** with comprehensive scenario coverage
- **Code review assistants** with improvement recommendations

### 3. **Educational Platforms**
- **Personalized tutoring** with adaptive difficulty and explanations
- **Interactive learning** with question generation and assessment
- **Curriculum development** with age-appropriate content creation
- **Language learning** with conversation practice and corrections

### 4. **Business Intelligence**
- **Report automation** with data interpretation and insights
- **Market analysis** with trend identification and forecasting
- **Customer service** with intelligent response suggestions
- **Process optimization** with workflow analysis and recommendations

## Testing

```bash
# Start the server
cargo run -p sampling-server &

# Test basic sampling functionality
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{"method": "sampling/createMessage", "params": {"messages": [{"role": "user", "content": {"type": "text", "text": "Hello!"}}]}}'

# Test tool integration
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{"method": "tools/call", "params": {"name": "basic_sampling", "arguments": {"prompt": "Test prompt"}}}'

# Test advanced features
curl -X POST http://127.0.0.1:8051/mcp \
  -H "Content-Type: application/json" \
  -d '{"method": "tools/call", "params": {"name": "advanced_sampling_demo", "arguments": {"task_type": "analysis"}}}'
```

This sampling server example demonstrates the full potential of MCP sampling for AI-assisted workflows, providing a foundation for building intelligent applications that leverage AI model capabilities while maintaining clean separation between server logic and AI generation.